# -*- coding: utf-8 -*-
"""ASSIGNMENT WEEK 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MGkVVOXw4a_xuUxSCsrpIk_AO-6PXKNt
"""

import pandas as pd
# Import pandas for data handling

# NumPy for numerical operations
import numpy as np

# Load the Iris dataset from sklearn
from sklearn.datasets import load_iris

# Tools for splitting data into train and test sets
from sklearn.model_selection import train_test_split

# For converting labels (species) into numbers
from sklearn.preprocessing import LabelEncoder

# Decision Tree classifier model
from sklearn.tree import DecisionTreeClassifier

# Metrics to evaluate the model
from sklearn.metrics import accuracy_score, precision_score, recall_score

# Load the Iris dataset
iris = load_iris()

# Store features (sepal/petal length & width) in a DataFrame
X = pd.DataFrame(iris.data, columns=iris.feature_names)

# Store target labels (species) in a separate Series
y = pd.Series(iris.target, name='species')

# Map numeric labels to actual species names
label_mapping = dict(zip(range(3), iris.target_names))
y = y.map(label_mapping)

# Check if any features have missing values
print("Missing values in each feature:\n", X.isnull().sum())

# Display the first 10 rows of the dataset
iris_df.head(10)

# display dataset information
iris_df.info()

# Show summary statistics (mean, std, min, max, etc.) for each feature in the dataset
iris_df.describe()

# Plot histograms of each feature (sepal/petal length and width) for each iris species
iris_df.hist(by='species', figsize=(12, 8), layout=(2, 2), sharex=False, sharey=False)
# Set a main title for all subplots
plt.suptitle("Feature Distributions by Species")
# Adjust spacing to prevent overlap between plots
plt.tight_layout()
# Display the plots
plt.show()

# Import LabelEncoder to convert text labels (like 'setosa') into numbers
from sklearn.preprocessing import LabelEncoder
# Import train_test_split to divide the dataset into training and testing parts
from sklearn.model_selection import train_test_split

# Create an instance of LabelEncoder to convert species names into numeric values
label_encoder = LabelEncoder()
# Apply the label encoder to the 'species' column and create a new column 'species_encoded'
iris_df['species_encoded'] = label_encoder.fit_transform(iris_df['species'])

X = iris_df.drop(columns=['species', 'species_encoded'])
y = iris_df['species_encoded']

# Split the dataset into 80% training and 20% test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Import evaluation metrics to assess the performance of the model
from sklearn.tree import DecisionTreeClassifier

# Create a Decision Tree classifier model with a fixed random seed for reproducibility
model = DecisionTreeClassifier(random_state=42)
# Train (fit) the model using the training data
model.fit(X_train, y_train)

# Import evaluation metrics to assess the performance of the model
from sklearn.metrics import accuracy_score, precision_score, recall_score

# Calculate the accuracy: overall percentage of correct predictions
accuracy = accuracy_score(y_test, y_pred)
# Calculate precision: how many selected items were relevant (average='macro' means treat all classes equally)
precision = precision_score(y_test, y_pred, average='macro')
# Calculate recall: how many relevant items were selected (macro averages across all classes equally)
recall = recall_score(y_test, y_pred, average='macro')

# Use the trained model to predict the species for the test data
y_pred = model.predict(X_test)

# Print the model's accuracy (how many predictions were correct overall)
print(f"Accuracy: {accuracy:.2f}")
# Print the model's precision (how many predicted positives were actually correct)
print(f"Precision: {precision:.2f}")
# Print the model's recall (how many actual positives the model correctly identified)
print(f"Recall: {recall:.2f}")